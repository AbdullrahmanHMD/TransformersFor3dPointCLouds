{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import ModelNet40, collate_fn\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "from model3 import Encoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torch\n",
    "from evaluate import *\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/users/ahamadeh18/COMP390/ModelNet40\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "modelnet40_path = os.path.join(os.getcwd(), 'ModelNet40')\n",
    "os.chdir('TransformersFor3dPointCLouds')\n",
    "print(modelnet40_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initalizing the training set DataLoader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 256\n",
    "TEST = False\n",
    "SAMPLING_METHOD = 'fps'\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ModelNet40(dataset_path=modelnet40_path, test=TEST, sample_size=SAMPLE_SIZE, sampling=SAMPLING_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ind_dist = dataset.class_indicies_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfit_classes_num = 4\n",
    "OVERFITTING_SAMPLE_SIZE = 10\n",
    "overfitting_set = []\n",
    "# overfitting_set = torch.randperm(len(dataset))[:30].tolist()\n",
    "# print(overfitting_set)\n",
    "for i in range(overfit_classes_num):\n",
    "    overfitting_set += class_ind_dist[i][:OVERFITTING_SAMPLE_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitting_subset = Subset(dataset, overfitting_set)\n",
    "overfitting_loader = DataLoader(overfitting_subset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import NLLLoss\n",
    "\n",
    "# class_weights =  torch.tensor(dataset.class_weights).float()\n",
    "# criterion = CrossEntropyLoss(weight=class_weights)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying the new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = 3\n",
    "embed_dim = 256\n",
    "out_dims = 8\n",
    "num_layers = 6\n",
    "num_heads = 1\n",
    "num_classes = 40\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Encoder(input_size=SAMPLE_SIZE, input_dims=input_dims, embed_dim=embed_dim, \n",
    "                out_dims=out_dims, num_layers=num_layers, num_heads=num_heads,\n",
    "                num_classes=num_classes, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x2b42668cda90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD, Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "\n",
    "parameters = model.parameters()\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-1\n",
    "momentum = 0.9\n",
    "\n",
    "# optimizer = SGD(parameters, lr=learning_rate, momentum=momentum)\n",
    "optimizer = Adam(parameters, lr=learning_rate, amsgrad=True)\n",
    "epochs = 20\n",
    "# step = len(dataset)\n",
    "# scheduler = CosineAnnealingLR(optimizer, step)\n",
    "scheduler = StepLR(optimizer=optimizer, step_size=epochs // 4, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:22<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | loss: 11.237439751625061\n",
      "Epoch time: 22.815608024597168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss: 6.854628145694733\n",
      "Epoch time: 13.551179647445679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | loss: 5.007630884647369\n",
      "Epoch time: 13.621806621551514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | loss: 4.83168226480484\n",
      "Epoch time: 13.912803173065186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 | loss: 1.7193366289138794\n",
      "Epoch time: 13.60151195526123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 | loss: 3.4946757555007935\n",
      "Epoch time: 13.4259614944458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 | loss: 2.3331241756677628\n",
      "Epoch time: 13.460626125335693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 | loss: 2.967472016811371\n",
      "Epoch time: 13.371336460113525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 | loss: 1.0369397103786469\n",
      "Epoch time: 13.367673873901367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 | loss: 1.359598308801651\n",
      "Epoch time: 13.252751111984253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 | loss: 0.20031534135341644\n",
      "Epoch time: 13.391286134719849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 | loss: 0.7006135970586911\n",
      "Epoch time: 13.348002195358276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 | loss: 0.02615960198454559\n",
      "Epoch time: 13.4698486328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 | loss: 0.031037640990689397\n",
      "Epoch time: 13.573632955551147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 | loss: 0.008697920507984236\n",
      "Epoch time: 13.516157865524292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 | loss: 0.007635055459104478\n",
      "Epoch time: 13.517062187194824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 | loss: 0.008424028375884518\n",
      "Epoch time: 13.488368272781372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17 | loss: 0.005474494450027123\n",
      "Epoch time: 13.717102766036987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18 | loss: 0.0031243949488271028\n",
      "Epoch time: 13.531246900558472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19 | loss: 0.001939417328685522\n",
      "Epoch time: 13.496321678161621\n",
      "Final loss 0.001939417328685522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# scheduler = None\n",
    "loss = train(model=model, optimizer=optimizer,\n",
    "          scheduler=scheduler, train_loader=overfitting_loader,\n",
    "          criterion=criterion, epochs=epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b4286dde320>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.43s/it]\n"
     ]
    }
   ],
   "source": [
    "accuracy = eval_2(model, overfitting_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.0%\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of trying the new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training the actual model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the dataset and splitting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 256\n",
    "TEST = False\n",
    "SAMPLING_METHOD = 'fps'\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ModelNet40(dataset_path=modelnet40_path, test=False, sample_size=SAMPLE_SIZE, sampling=SAMPLING_METHOD)\n",
    "test_dataset = ModelNet40(dataset_path=modelnet40_path, test=True, sample_size=SAMPLE_SIZE, sampling=SAMPLING_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = 0.9\n",
    "\n",
    "N = len(train_dataset)\n",
    "\n",
    "n_train = int(N * 0.9)\n",
    "n_validation = N - n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, validation_set = torch.utils.data.random_split(train_dataset, [n_train , n_validation])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, collate_fn=collate_fn)\n",
    "validation_loader = DataLoader(dataset=validation_set, batch_size=batch_size, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims = 3\n",
    "embed_dim = 256\n",
    "out_dims = 8\n",
    "num_layers = 6\n",
    "num_heads = 1\n",
    "num_classes = 40\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(input_size=SAMPLE_SIZE, input_dims=input_dims, embed_dim=embed_dim, \n",
    "                out_dims=out_dims, num_layers=num_layers, num_heads=num_heads,\n",
    "                num_classes=num_classes, dropout=dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "parameters = model.parameters()\n",
    "learning_rate = 1e-4\n",
    "momentum = 0.9\n",
    "weight_decay = 1e-4\n",
    "\n",
    "optimizer = SGD(parameters, lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# step = len(train_dataset)\n",
    "# scheduler = CosineAnnealingLR(optimizer, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class_weights =  torch.tensor(train_dataset.class_weights).float().to(device=device)\n",
    "criterion = CrossEntropyLoss(weight=class_weights).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5/70 [03:43<48:22, 44.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9929723aabe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m loss = train(model=model, optimizer=optimizer,\n\u001b[1;32m      4\u001b[0m           \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           criterion=criterion, epochs=epochs, verbose=False)\n\u001b[0m",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, train_loader, criterion, epochs, save_params, verbose, load_model)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mepoch_tic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fps'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAMPLE_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/data/dataset.py\u001b[0m in \u001b[0;36mfps\u001b[0;34m(self, points, n_samples)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             dist_to_last_added_point = (\n\u001b[0;32m--> 232\u001b[0;31m                 (points[last_added] - points[points_left])**2).sum(-1) # [P - i]\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# If closer, updated distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "scheduler = None\n",
    "loss = train(model=model, optimizer=optimizer,\n",
    "          scheduler=scheduler, train_loader=train_loader,\n",
    "          criterion=criterion, epochs=epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = eval_2(model, overfitting_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset[0][0].view(1, 128, 3)\n",
    "yhat = model(x.float())\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kuacc/apps/anaconda/5.2.0/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = torch.nn.Softmax()(yhat)\n",
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 3\n",
    "feature_dim = 128\n",
    "out_features = 1024\n",
    "decoder_features = 256\n",
    "k_size = 4\n",
    "NUM_CLASSES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointCloudClassifier(in_features, feature_dim, out_features, decoder_features, k_size, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 128\n",
    "TEST = False\n",
    "SAMPLING_METHOD = 'fps'\n",
    "\n",
    "model_net40 = ModelNet40(dataset_path=modelnet40_path, test=TEST, sample_size=SAMPLE_SIZE, sampling=SAMPLING_METHOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "parameters = model.parameters()\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = SGD(parameters, lr=learning_rate, momentum=momentum)\n",
    "\n",
    "step = len(model_net40)\n",
    "scheduler = CosineAnnealingLR(optimizer, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import NLLLoss\n",
    "\n",
    "class_weights =  torch.tensor(model_net40.class_weights).float()\n",
    "criterion = CrossEntropyLoss(weight=class_weights)\n",
    "# criterion = NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitting_data = []\n",
    "for i in range(20):\n",
    "    overfitting_data.append(model_net40[i])\n",
    "overfitting_loader = DataLoader(overfitting_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_214362/1648876592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m loss = train(model=model, optimizer=optimizer,\n\u001b[1;32m      4\u001b[0m           \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverfitting_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           criterion=criterion, epochs=epochs, verbose=False)\n\u001b[0m",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, train_loader, criterion, epochs, save_params, verbose, load_model)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mmax_pool_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mavg_pool_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0matten_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0matten_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matten_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0matten_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matten_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mallignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dim\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0matten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mallignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0matten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_O\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 3D"
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "epochs = 15\n",
    "loss = train(model=model, optimizer=optimizer,\n",
    "          scheduler=scheduler, train_loader=overfitting_loader,\n",
    "          criterion=criterion, epochs=epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b0262ff7710>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = model(model_net40[0][0].float())\n",
    "(torch.argmax(x_test) == model_net40[0][1]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46.0388, -0.1911, -1.2720, -0.5212, -1.1767, -1.7760, -1.1018, -1.4636,\n",
       "        -0.6017, -0.4255, -1.2653, -1.4788, -0.7948, -1.6204, -1.0603, -1.0340,\n",
       "        -1.2143, -0.8255, -1.5459, -1.4086,  0.1541, -1.1079, -1.7431, -0.3271,\n",
       "        -1.8796, -1.3339, -1.5646, -0.3407, -1.3065, -0.4129, -1.1565, -0.8027,\n",
       "        -0.9239, -1.6641, -1.1740, -1.9464, -1.5179, -0.6686, -1.0703, -1.2988],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+00, 8.3673e-21, 2.8389e-21, 6.0151e-21, 3.1229e-21, 1.7150e-21,\n",
      "        3.3658e-21, 2.3441e-21, 5.5498e-21, 6.6193e-21, 2.8580e-21, 2.3086e-21,\n",
      "        4.5752e-21, 2.0039e-21, 3.5083e-21, 3.6019e-21, 3.0076e-21, 4.4369e-21,\n",
      "        2.1588e-21, 2.4764e-21, 1.1818e-20, 3.3454e-21, 1.7724e-21, 7.3036e-21,\n",
      "        1.5462e-21, 2.6687e-21, 2.1187e-21, 7.2045e-21, 2.7427e-21, 6.7033e-21,\n",
      "        3.1866e-21, 4.5392e-21, 4.0209e-21, 1.9182e-21, 3.1314e-21, 1.4463e-21,\n",
      "        2.2201e-21, 5.1906e-21, 3.4735e-21, 2.7640e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.Softmax(dim=0)(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointCloudClassifier(in_features, feature_dim, out_features, k_size, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(model_net40, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "parameters = model.parameters()\n",
    "learning_rate = 1e-4\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = SGD(parameters, lr=learning_rate, momentum=momentum)\n",
    "\n",
    "step = len(model_net40)\n",
    "scheduler = CosineAnnealingLR(optimizer, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import NLLLoss\n",
    "\n",
    "class_weights = torch.tensor(model_net40.class_weights).float()\n",
    "criterion = CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [27:27<00:00, 21.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | loss: 290.16918444633484\n",
      "Epoch time: 1647.4102654457092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [27:25<00:00, 21.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss: 290.5951235294342\n",
      "Epoch time: 1645.5314455032349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [27:26<00:00, 21.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 | loss: 290.51247549057007\n",
      "Epoch time: 1646.2706401348114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [27:26<00:00, 21.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 | loss: 289.8480145931244\n",
      "Epoch time: 1646.2923140525818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 26/77 [09:14<16:21, 19.24s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "loss = train(model=model, optimizer=optimizer,\n",
    "          scheduler=scheduler, train_loader=train_loader,\n",
    "          criterion=criterion, epochs=epochs, save_params=True, verbose=False, load_model=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 128\n",
    "TEST = True\n",
    "SAMPLING_METHOD = 'fps'\n",
    "batch_size = 1\n",
    "\n",
    "model_net_256_test = ModelNet40(dataset_path=modelnet40_path, test=TEST, sample_size=SAMPLE_SIZE, sampling=SAMPLING_METHOD)\n",
    "test_laoder = DataLoader(model_net_256_test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, model_net_256_test, epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, model_net_256_test, epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label, _ = model_net_256_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model(data.float())\n",
    "print(label)\n",
    "print((torch.argmax(yhat) == label).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "N = len(model_net_256_test)\n",
    "model.eval()\n",
    "for point in model_net_256_test:\n",
    "    if point == None:\n",
    "        N -= 1\n",
    "        continue\n",
    "    x, y, _ = point\n",
    "    yhat = model(x.float())\n",
    "    \n",
    "    if (torch.argmax(yhat) == y).item():\n",
    "        accuracy += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pc_transformer",
   "language": "python",
   "name": "pc_transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
