{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a38287e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4979db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.dataset import ModelNet40, collate_fn\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "from model import *\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435b41b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce38ab7",
   "metadata": {},
   "source": [
    "### Getting the dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "255505db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/users/ahamadeh18/COMP390/ModelNet40\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "modelnet40_path = os.path.join(os.getcwd(), 'ModelNet40')\n",
    "os.chdir('TransformersFor3dPointCLouds')\n",
    "print(modelnet40_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8e127",
   "metadata": {},
   "source": [
    "### Initalizing the training set DataLoader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514172f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 128\n",
    "TEST = False\n",
    "SAMPLING_METHOD = 'fps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d495aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_net40 = ModelNet40(dataset_path=modelnet40_path, test=TEST, sample_size=SAMPLE_SIZE, sampling=SAMPLING_METHOD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca72db85",
   "metadata": {},
   "source": [
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f605faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 3\n",
    "feature_dim = 128\n",
    "out_features = 1024\n",
    "k_size = 4\n",
    "NUM_CLASSES = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbccfaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointCloudClassifier(in_features, feature_dim, out_features, k_size, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508e18d7",
   "metadata": {},
   "source": [
    "## Training specifications:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ab2fb",
   "metadata": {},
   "source": [
    "### Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e65b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "parameters = model.parameters()\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = SGD(parameters, lr=learning_rate, momentum=momentum)\n",
    "\n",
    "step = len(model_net40)\n",
    "scheduler = CosineAnnealingLR(optimizer, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464d4f1",
   "metadata": {},
   "source": [
    "### Loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0abb42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import NLLLoss\n",
    "\n",
    "class_weights =  torch.tensor(model_net40.class_weights).float()\n",
    "criterion = CrossEntropyLoss(weight=class_weights)\n",
    "# criterion = NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92cffa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "overfitting_data = []\n",
    "for i in range(20):\n",
    "    overfitting_data.append(model_net40[i])\n",
    "overfitting_loader = DataLoader(overfitting_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a9397b",
   "metadata": {},
   "source": [
    "## Overfitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d2a50b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "t() expects a tensor with <= 2 dimensions, but self is 3D",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_214362/1648876592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m loss = train(model=model, optimizer=optimizer,\n\u001b[1;32m      4\u001b[0m           \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverfitting_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           criterion=criterion, epochs=epochs, verbose=False)\n\u001b[0m",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, train_loader, criterion, epochs, save_params, verbose, load_model)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mmax_pool_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mavg_pool_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0matten_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0matten_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matten_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0matten_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matten_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/users/ahamadeh18/COMP390/TransformersFor3dPointCLouds/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_Q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_V\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mallignment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dim\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0matten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mallignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0matten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_O\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: t() expects a tensor with <= 2 dimensions, but self is 3D"
     ]
    }
   ],
   "source": [
    "from train import train\n",
    "epochs = 15\n",
    "loss = train(model=model, optimizer=optimizer,\n",
    "          scheduler=scheduler, train_loader=overfitting_loader,\n",
    "          criterion=criterion, epochs=epochs, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc02427b",
   "metadata": {},
   "source": [
    "### Plotting the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87796ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b0262ff7710>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAWgElEQVR4nO3df5BdZX3H8fdnf2Tv5tfeQBbC3gSWVtRRRgVXBPHXgNhIKWlHHGVaRNRJdbSAMNOKnUHlj1bbDljEymSUBlsGsUA1ahRRKGBVZInhZ1BSFcmSkCWQzS/yY7Pf/nHPJsuym3uT3N1zzzmf18xOzj3n2Xu+MJtPnn3u85xHEYGZmWVfS9oFmJlZYzjQzcxywoFuZpYTDnQzs5xwoJuZ5URbWjeeP39+9Pb2pnV7M7NMevDBB5+LiO6JrqUW6L29vfT396d1ezOzTJL01GTXPORiZpYTDnQzs5xwoJuZ5YQD3cwsJxzoZmY54UA3M8sJB7qZWU5kLtCf2LCFf/rhEwzt2JN2KWZmTSVzgf6HTTv4t//5P556fnvapZiZNZXMBXpPuROAZza/mHIlZmbNJXOBvnBeNdAHNu9MuRIzs+aSuUDv6mxn5oxWBl5wD93MbKzMBbokesqdHnIxMxsnc4EOUCl38syQA93MbKxMBnpPudNDLmZm42Qy0CvlEpu272bnnr1pl2Jm1jRqBrqkkqRfSnpI0mOSPj9Bmw5Jt0haK+l+Sb1TUm2iMs9TF83Mxqunh74LOCMiXg+8AVgs6dRxbT4CvBARrwCuAb7Y0CrH6ekanbroQDczG1Uz0KNqW/KyPfmKcc2WADcmx7cCZ0pSw6ocx4uLzMxerq4xdEmtklYDG4E7I+L+cU0qwNMAETEMDAFHTvA+SyX1S+ofHBw85KIXdJVokRcXmZmNVVegR8TeiHgDsBA4RdKJh3KziFgWEX0R0dfdPeGm1XVpb23h6Lklz3QxMxvjoGa5RMRm4G5g8bhLA8AiAEltQBewqQH1TcqLi8zMXqqeWS7dksrJcSdwFvDEuGYrgAuT4/OAuyJi/Dh7Q/V4cZGZ2UvU00M/Brhb0sPAA1TH0L8n6SpJ5yZtvg4cKWktcBnw6akpd79KuZP1m3cyMjKl/26YmWVGW60GEfEwcNIE568cc7wTeF9jSzuwSrnE7r0jPLdtF0fNLU3nrc3MmlImV4rC/qmLnotuZlaV2UDfv1rUUxfNzCDDgb6/h74j5UrMzJpDZgN9bqmdOR1t7qGbmSUyG+hQHXbxGLqZWVWmA93PRTcz2y/jgV7y4iIzs0SmA71SnsnmHXvYvms47VLMzFKX6UDvKVcXFPmZLmZmGQ/0ihcXmZntk+1A9+IiM7N9Mh3oR80p0doiLy4yMyPjgd7aIhbMLbmHbmZGxgMdvLjIzGxU9gPdi4vMzIAcBHpPucSGLTvZ640uzKzgMh/olfJM9o4EG7d6HN3Mii3zgT66uMjDLmZWdJkPdC8uMjOrynygj2504amLZlZ0mQ/0WR1tlGe2e3GRmRVe5gMdoKer0z10Myu8moEuaZGkuyU9LukxSZdM0OadkoYkrU6+rpyacifWU+70ExfNrPDa6mgzDFweEaskzQEelHRnRDw+rt19EXFO40usbeG8Tu7/7aY0bm1m1jRq9tAjYn1ErEqOtwJrgMpUF3Ywesoltu4aZsvOPWmXYmaWmoMaQ5fUC5wE3D/B5dMkPSTpB5JeO8n3L5XUL6l/cHDw4KudxP6ZLh52MbPiqjvQJc0GbgMujYgt4y6vAo6LiNcDXwa+PdF7RMSyiOiLiL7u7u5DLPnl9s1F9+IiMyuwugJdUjvVML8pIm4ffz0itkTEtuR4JdAuaX5DKz2AinvoZmZ1zXIR8HVgTURcPUmbBUk7JJ2SvO+0fUo5f3YHM1pbGPDURTMrsHpmuZwOXAA8Iml1cu4zwLEAEXE9cB7wcUnDwIvAByJi2h5/2NIijimX3EM3s0KrGegR8VNANdpcB1zXqKIORU+XN7ows2LLxUpR8OIiM7PcBHplXifPbtnJnr0jaZdiZpaK/AR6ucRIwIYhfzBqZsWUm0D34iIzK7rcBPq+uehDDnQzK6bcBHqPV4uaWcHlJtBL7a0cOWuGFxeZWWHlJtDBUxfNrNhyFeiVshcXmVlx5SrQR3vo0/jUATOzppGzQC+xY/dehl70RhdmVjy5CvSF86ozXdZ5pouZFVCuAt2Li8ysyBzoZmY5katAP3LWDDraWjzTxcwKKVeBLolKuZNnvLjIzAooV4EO1WEX99DNrIhyF+heXGRmRZW7QO8pdzK4dRe7hvemXYqZ2bTKYaCXAG90YWbFk7tAr8zzY3TNrJjyF+ijz0X3OLqZFUzNQJe0SNLdkh6X9JikSyZoI0nXSlor6WFJJ09NubUt6KoOuXjqopkVTVsdbYaByyNilaQ5wIOS7oyIx8e0eQ9wQvL1ZuCryZ/TrqOtlaPmdHi1qJkVTs0eekSsj4hVyfFWYA1QGddsCfCNqPoFUJZ0TMOrrZPnoptZER3UGLqkXuAk4P5xlyrA02Ner+PloT9tKt65yMwKqO5AlzQbuA24NCK2HMrNJC2V1C+pf3Bw8FDeoi495RID3ujCzAqmrkCX1E41zG+KiNsnaDIALBrzemFy7iUiYllE9EVEX3d396HUW5dKuZNdwyNs2r57yu5hZtZs6pnlIuDrwJqIuHqSZiuADyazXU4FhiJifQPrPCh+jK6ZFVE9s1xOBy4AHpG0Ojn3GeBYgIi4HlgJnA2sBXYAFzW80oMwNtBft7CcZilmZtOmZqBHxE8B1WgTwCcaVdTh8lZ0ZlZEuVspCtDV2c7MGa1eXGRmhZLLQJdEj6cumlnB5DLQwc9FN7PiyW2gu4duZkWT20CvlEts2r6bnXu80YWZFUN+A32eH6NrZsWS20Dv6fLiIjMrlvwGuleLmlnB5DbQF3SVaJG3ojOz4shtoLe3tnD03BIDXlxkZgWR20AHT100s2LJdaB7cZGZFUmuA72n3Mn6oRcZGfFGF2aWf7kO9Eq5xJ69wXPbdqVdipnZlMt3oI8+RtfDLmZWALkOdM9FN7MicaCbmeVErgN9bqmdOR1tXlxkZoWQ60CH6ji6FxeZWRHkPtC9uMjMiqIAgV7imSEHupnlX+4DvVKeyeYde9i+azjtUszMplTNQJd0g6SNkh6d5Po7JQ1JWp18Xdn4Mg9dT7kEeKaLmeVfPT305cDiGm3ui4g3JF9XHX5ZjVMpe+ciMyuGmoEeEfcCz09DLVPCW9GZWVE0agz9NEkPSfqBpNc26D0b4qg5JVpb5CEXM8u9tga8xyrguIjYJuls4NvACRM1lLQUWApw7LHHNuDWtbW2iAVzSzzjuehmlnOH3UOPiC0RsS05Xgm0S5o/SdtlEdEXEX3d3d2He+u6VeZ1erWomeXeYQe6pAWSlByfkrznpsN930byRhdmVgQ1h1wk3Qy8E5gvaR3wWaAdICKuB84DPi5pGHgR+EBENNWOEj3lEhu27GTvSNDaorTLMTObEjUDPSLOr3H9OuC6hlU0BSrlmewdCZ7dsnPfExjNzPIm9ytFwYuLzKwYChHoXlxkZkVQiEDvcaCbWQEUItBndbRRntnuIRczy7VCBDpAT1enFxeZWa4VJ9DLXlxkZvlWmEBfOM87F5lZvhUm0HvKJbbuGmbLzj1pl2JmNiUKFOjJTBcPu5hZThUm0EfnonvYxczyyoFuZpYThQn0+bM7mNHawjoHupnlVGECvaVFHFP2Rhdmll+FCXQYXVzkHrqZ5VOxAt2Li8wsxwoV6JV5nTy7dSd79o6kXYqZWcMVK9DLJSJgw5DH0c0sfwoV6D2eumhmOVaoQPdGF2aWZ4UKdPfQzSzPChXopfZWjpw1gwHPRTezHCpUoEN1pouHXMwsjwoX6F5cZGZ5VTPQJd0gaaOkRye5LknXSlor6WFJJze+zMbpKVcDPSLSLsXMrKHq6aEvBxYf4Pp7gBOSr6XAVw+/rKlTmdfJjt172bzDG12YWb7UDPSIuBd4/gBNlgDfiKpfAGVJxzSqwEarlEuApy6aWf40Ygy9Ajw95vW65NzLSFoqqV9S/+DgYANuffA8ddHM8mpaPxSNiGUR0RcRfd3d3dN56316vLjIzHKqEYE+ACwa83phcq4pHTlrBh1tLe6hm1nuNCLQVwAfTGa7nAoMRcT6BrzvlJBEpdzpjS7MLHfaajWQdDPwTmC+pHXAZ4F2gIi4HlgJnA2sBXYAF01VsY3SU+70VnRmljs1Az0izq9xPYBPNKyiaVApd3LXrzemXYaZWUMVbqUoVHvog1t3sWt4b9qlmJk1TEEDvToXfb3H0c0sRwoZ6JV5notuZvlTzED3XHQzy6FCBvqCLi//N7P8KWSgd7S1ctScDg+5mFmuFDLQYfQxuv5Q1Mzyo7CBXil75yIzy5fiBnqyFZ03ujCzvChsoPd0ldg9PMKm7bvTLsXMrCGKG+h+LrqZ5UxhA310cdHACw50M8uH4ga6FxeZWc4UNtC7OtuZOaPVUxfNLDcKG+iS6Cl3MrB5R9qlmJk1RGEDHfDORWaWK4UO9OpqUY+hm1k+FDrQK+USm7bv5sXd3ujCzLKv2IE++lz0IffSzSz7Ch3oPV1eXGRm+VHsQC97cZGZ5UehA31BV4kWuYduZvlQV6BLWizp15LWSvr0BNc/JGlQ0urk66ONL7Xx2ltbOHpuiQFPXTSzHGir1UBSK/AV4CxgHfCApBUR8fi4prdExCenoMYp5cVFZpYX9fTQTwHWRsRvI2I38E1gydSWNX28uMjM8qKeQK8AT495vS45N957JT0s6VZJiyZ6I0lLJfVL6h8cHDyEchuvp9zJ+qEXGRnxRhdmlm2N+lD0u0BvRLwOuBO4caJGEbEsIvoioq+7u7tBtz48lXKJPXuDwW270i7FzOyw1BPoA8DYHvfC5Nw+EbEpIkYT8WvAGxtT3tTb91x0z3Qxs4yrJ9AfAE6QdLykGcAHgBVjG0g6ZszLc4E1jStxannnIjPLi5qzXCJiWNIngTuAVuCGiHhM0lVAf0SsAC6WdC4wDDwPfGgKa24oLy4ys7yoGegAEbESWDnu3JVjjq8ArmhsadNjbqmdOaU299DNLPMKvVJ0VKXc6cVFZpZ5DnRGFxe5h25m2eZAB3rKJQ+5mFnmOdCBSnkmQy/uYduu4bRLMTM7ZA50qj108NRFM8s2BzrVD0XBi4vMLNsc6IzZis6BbmYZ5kAHjppTorVFDnQzyzQHOtDaIhbMLXm1qJllmgM9UZnn56KbWbY50BMLy52s2bCFB596Pu1SzMwOiQM98eG3Hs/cUjvnXf9zPvudRz0n3cwyx4GeOLHSxR2fejsXntbLN37xFO+++h7ufmJj2mWZmdXNgT7G7I42Pnfua7n1Y29hZkcbFy1/gEu++Ss2eTcjM8sAB/oE3njcPL5/8Vu55MwTWPnIet519T18+1cDRHjfUTNrXg70SXS0tfKps17J9y9+G73zZ3HpLau5aPkDrHthR9qlmZlNyIFewyuPnsOtH3sLn/2z1/DL3z3Pu6+5l+X/+zv2jri3bmbNxYFeh9YWcdHpx3PHpW+nr/cIPvfdx3nf9T/jyWe3pl2amdk+DvSDsOiImdx40Zu45v2v53fPbefsa+/jSz/+DbuHR9IuzczMgX6wJPEXJy3kzsvewXtOPIYv/fhJzvnyfaz6wwtpl2ZmBedAP0TzZ3dw7fknccOH+ti2c5j3fvVnfP67j7HdC5LMLCUO9MN0xquP5keXvYMLTj2O5T/7Pe++5l7u+c1g2mWZWQHVFeiSFkv6taS1kj49wfUOSbck1++X1NvwSpvY7I42rlpyIv/116dRam/hwht+yWW3rOb57bvTLs3MCqRmoEtqBb4CvAd4DXC+pNeMa/YR4IWIeAVwDfDFRheaBX29R/D9i9/GxWe8ghUPPcNZV9/Dd1Z7QZKZTQ/VChtJpwGfi4g/SV5fARAR/zimzR1Jm59LagM2AN1xgDfv6+uL/v7+BvwnNKcnNmzh7257hIee3sysGa20SCBokUgO9x2DaBFo9DrVD1+VnNO+66PX9h+bWfa8/02L+Ojb/uiQvlfSgxHRN9G1tjq+vwI8Peb1OuDNk7WJiGFJQ8CRwHPjClkKLAU49thj6yo+q169YC63f/wtfKv/adZu3EYEBFH9M4KRMa+ra5RGj/efCwJGz8H+6+Bev1mGzZ/dMSXvW0+gN0xELAOWQbWHPp33TkNrizj/lHz/w2VmzaOeD0UHgEVjXi9Mzk3YJhly6QI2NaJAMzOrTz2B/gBwgqTjJc0APgCsGNdmBXBhcnwecNeBxs/NzKzxag65JGPinwTuAFqBGyLiMUlXAf0RsQL4OvAfktYCz1MNfTMzm0Z1jaFHxEpg5bhzV4453gm8r7GlmZnZwfBKUTOznHCgm5nlhAPdzCwnHOhmZjlRc+n/lN1YGgSeOsRvn8+4VahNLkv1ZqlWyFa9WaoVslVvlmqFw6v3uIjonuhCaoF+OCT1T/Ysg2aUpXqzVCtkq94s1QrZqjdLtcLU1eshFzOznHCgm5nlRFYDfVnaBRykLNWbpVohW/VmqVbIVr1ZqhWmqN5MjqGbmdnLZbWHbmZm4zjQzcxyInOBXmvD6mYhaZGkuyU9LukxSZekXVM9JLVK+pWk76Vdy4FIKku6VdITktYkWyU2LUmfSn4OHpV0s6RS2jWNJekGSRslPTrm3BGS7pT0ZPLnvDRrHDVJrf+c/Cw8LOm/JZVTLPElJqp3zLXLJYWk+Y24V6YCvc4Nq5vFMHB5RLwGOBX4RBPXOtYlwJq0i6jDvwI/jIhXA6+niWuWVAEuBvoi4kSqj6FutkdMLwcWjzv3aeAnEXEC8JPkdTNYzstrvRM4MSJeB/wGuGK6izqA5by8XiQtAt4N/KFRN8pUoAOnAGsj4rcRsRv4JrAk5ZomFBHrI2JVcryVauBU0q3qwCQtBP4U+FratRyIpC7g7VSfw09E7I6IzakWVVsb0Jns6DUTeCblel4iIu6lupfBWEuAG5PjG4E/n86aJjNRrRHxo4gYTl7+gurOak1hkv+3ANcAfws0bGZK1gJ9og2rmzokAST1AicB96dcSi1fovoDNpJyHbUcDwwC/54MD31N0qy0i5pMRAwA/0K1J7YeGIqIH6VbVV2Ojoj1yfEG4Og0izkIHwZ+kHYRByJpCTAQEQ818n2zFuiZI2k2cBtwaURsSbueyUg6B9gYEQ+mXUsd2oCTga9GxEnAdppnOOBlkrHnJVT/IeoBZkn6q3SrOjjJlpJNP8dZ0t9THe68Ke1aJiNpJvAZ4MpabQ9W1gK9ng2rm4akdqphflNE3J52PTWcDpwr6fdUh7LOkPSf6ZY0qXXAuogY/Y3nVqoB36zeBfwuIgYjYg9wO/CWlGuqx7OSjgFI/tyYcj0HJOlDwDnAXzb5nsZ/TPUf94eSv28LgVWSFhzuG2ct0OvZsLopSBLVMd41EXF12vXUEhFXRMTCiOil+v/1rohoyl5kRGwAnpb0quTUmcDjKZZUyx+AUyXNTH4uzqSJP8QdY+zm7xcC30mxlgOStJjqcOG5EbEj7XoOJCIeiYijIqI3+fu2Djg5+bk+LJkK9ORDj9ENq9cA34qIx9KtalKnAxdQ7emuTr7OTruoHPkb4CZJDwNvAP4h3XIml/wmcSuwCniE6t+7plqqLulm4OfAqyStk/QR4AvAWZKepPpbxhfSrHHUJLVeB8wB7kz+rl2fapFjTFLv1NyruX8zMTOzemWqh25mZpNzoJuZ5YQD3cwsJxzoZmY54UA3M8sJB7qZWU440M3McuL/AbUXSy7nTpjrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a33e1bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = model(model_net40[0][0].float())\n",
    "(torch.argmax(x_test) == model_net40[0][1]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02450136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46.0388, -0.1911, -1.2720, -0.5212, -1.1767, -1.7760, -1.1018, -1.4636,\n",
       "        -0.6017, -0.4255, -1.2653, -1.4788, -0.7948, -1.6204, -1.0603, -1.0340,\n",
       "        -1.2143, -0.8255, -1.5459, -1.4086,  0.1541, -1.1079, -1.7431, -0.3271,\n",
       "        -1.8796, -1.3339, -1.5646, -0.3407, -1.3065, -0.4129, -1.1565, -0.8027,\n",
       "        -0.9239, -1.6641, -1.1740, -1.9464, -1.5179, -0.6686, -1.0703, -1.2988],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c9fad15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000e+00, 8.3673e-21, 2.8389e-21, 6.0151e-21, 3.1229e-21, 1.7150e-21,\n",
      "        3.3658e-21, 2.3441e-21, 5.5498e-21, 6.6193e-21, 2.8580e-21, 2.3086e-21,\n",
      "        4.5752e-21, 2.0039e-21, 3.5083e-21, 3.6019e-21, 3.0076e-21, 4.4369e-21,\n",
      "        2.1588e-21, 2.4764e-21, 1.1818e-20, 3.3454e-21, 1.7724e-21, 7.3036e-21,\n",
      "        1.5462e-21, 2.6687e-21, 2.1187e-21, 7.2045e-21, 2.7427e-21, 6.7033e-21,\n",
      "        3.1866e-21, 4.5392e-21, 4.0209e-21, 1.9182e-21, 3.1314e-21, 1.4463e-21,\n",
      "        2.2201e-21, 5.1906e-21, 3.4735e-21, 2.7640e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.nn.Softmax(dim=0)(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a644fc3",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c099ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PointCloudClassifier(in_features, feature_dim, out_features, k_size, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0163d1ca",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a83844b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 128\n",
    "TEST = False\n",
    "SAMPLING_METHOD = 'fps'\n",
    "\n",
    "model_net40 = ModelNet40(dataset_path=modelnet40_path, test=TEST, sample_size=SAMPLE_SIZE, sampling=SAMPLING_METHOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0daabc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5cd58f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(model_net40, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a0009",
   "metadata": {},
   "source": [
    "### Optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a47a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "parameters = model.parameters()\n",
    "learning_rate = 1e-4\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = SGD(parameters, lr=learning_rate, momentum=momentum)\n",
    "\n",
    "step = len(model_net40)\n",
    "scheduler = CosineAnnealingLR(optimizer, step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b9dbb",
   "metadata": {},
   "source": [
    "### Loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "804720a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn import NLLLoss\n",
    "\n",
    "class_weights =  torch.tensor(model_net40.class_weights).float()\n",
    "criterion = CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce61b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9843/9843 [1:41:44<00:00,  1.61it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | loss: 12083.202962384292\n",
      "Epoch time: 6104.91911649704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9843/9843 [2:59:17<00:00,  1.09s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 | loss: 15915.664114731015\n",
      "Epoch time: 10757.768959760666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2210/9843 [08:14<2:40:27,  1.26s/it]"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "loss = train(model=model, optimizer=optimizer,\n",
    "          scheduler=scheduler, train_loader=model_net40,\n",
    "          criterion=criterion, epochs=epochs, save_params=True, verbose=False, load_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0673a684",
   "metadata": {},
   "source": [
    "## Model Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbe2e6",
   "metadata": {},
   "source": [
    "### Loading the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7fda7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE = 128\n",
    "TEST = True\n",
    "SAMPLING_METHOD = 'fps'\n",
    "batch_size = 1\n",
    "\n",
    "model_net_256_test = ModelNet40(dataset_path=modelnet40_path, test=TEST, sample_size=SAMPLE_SIZE, sampling=SAMPLING_METHOD)\n",
    "test_laoder = DataLoader(model_net_256_test, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0077ad86",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, model_net_256_test, epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "982b5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label, _ = model_net_256_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4cb41350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "yhat = model(data.float())\n",
    "print(label)\n",
    "print((torch.argmax(yhat) == label).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9b3b5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "N = len(model_net_256_test)\n",
    "model.eval()\n",
    "for point in model_net_256_test:\n",
    "    if point == None:\n",
    "        N -= 1\n",
    "        continue\n",
    "    x, y, _ = point\n",
    "    yhat = model(x.float())\n",
    "    \n",
    "    if (torch.argmax(yhat) == y).item():\n",
    "        accuracy += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3ff98ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2b345950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0078060805258833195"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pc_transformer",
   "language": "python",
   "name": "pc_transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
